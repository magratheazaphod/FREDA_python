{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Highly similar to RDA_freq_diff.ipynb, except that this time we also port in decorrelation time scales (tau) from\n",
    "#  RDA_freq_tau.nc, and use those values to change the effective sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "#import masked arrays - important because intensity shows up as a NaN at some points\n",
    "%matplotlib notebook\n",
    "import numpy.ma as ma\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5179\n",
      "8007\n",
      "8093\n",
      "9407\n"
     ]
    }
   ],
   "source": [
    "## LOAD FROM NETCDF FILE ##\n",
    "savefile = \"RDA_hov_periods\"\n",
    "ferretpath = \"/Users/Siwen/Desktop/Ferret/bin/\"\n",
    "\n",
    "#netCDF output file formatting formatting\n",
    "hovname = ferretpath + savefile + \".nc\"\n",
    "hovnc = nc.Dataset(hovname, \"r\")\n",
    "\n",
    "#populate lists with intensity occupancy plots for each different time period (periods given below)\n",
    "p1_beg = [1951,1980]\n",
    "p1_end = [1979,1993]\n",
    "p2_beg = [1980,1994]\n",
    "p2_end = [2007,2007]\n",
    "\n",
    "#in this case, we're just going to load the smoothed plots of hovmoller frequency\n",
    "lats_1_p1 = []\n",
    "lats_p1 = []\n",
    "\n",
    "lats_1_p2 = []\n",
    "lats_p2 = []\n",
    "\n",
    "\n",
    "for p1_b, p1_e, p2_b, p2_e in zip(p1_beg, p1_end, p2_beg, p2_end):\n",
    "\n",
    "    years_p1= str(p1_b-1900) + str(\"{0:0=2d}\".format((p1_e-1900)%100))\n",
    "    print(years_p1)\n",
    "    years_p2= str(p2_b-1900) + str(\"{0:0=2d}\".format((p2_e-1900)%100))\n",
    "    print(years_p2)\n",
    "    \n",
    "    lats_1_p1.append(hovnc['lat_1_hov_smth_' + years_p1][:])\n",
    "    lats_p1.append(hovnc['lat_hov_smth_' + years_p1][:])\n",
    "    \n",
    "    lats_1_p2.append(hovnc['lat_1_hov_smth_' + years_p2][:])\n",
    "    lats_p2.append(hovnc['lat_hov_smth_' + years_p2][:])\n",
    "    \n",
    "hovnc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns the standard error for a Bernoulli variable with probability of success p and number\n",
    "#of trials n.\n",
    "def bernoulli_std(p, n):\n",
    "    s = (p*(1-p)/n)**.5\n",
    "    return s\n",
    "\n",
    "#performs bernoulli_std for each point in 2D numpy array F, returns array of standard deviations\n",
    "#F is a probability distributed between 0 and 1.\n",
    "\n",
    "#ALSO, compared with freq_std in RDA_freq_diff, incorporates decorrelation time scale tau, used to change\n",
    "#effective sample size N as n/tau, where n is total number of observations.\n",
    "def freq_std_tau(F, years, dayrange, latrange, tau):\n",
    "    S = np.zeros(F.shape)\n",
    "    ll = (latrange-1)/2\n",
    "    \n",
    "    for i in range(S.shape[0]):\n",
    "        for j in range(S.shape[1]):\n",
    "            \n",
    "            #have to adjust number of samples if we're at the edges\n",
    "            lrange = int(min(S.shape[1]-1,j+ll) - max(0,j-ll) + 1)\n",
    "            nn = (years*dayrange*lrange)/tau[i,j] ## EFFFECTIVE sample size scaled by autocorrelation tau\n",
    "            S[i,j] = bernoulli_std(F[i,j],nn)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## LOAD decorrelation timescales from RDA_freq_tau.nc\n",
    "savefile = \"RDA_freq_tau\"\n",
    "ferretpath = \"/Users/Siwen/Desktop/Ferret/bin/\"\n",
    "\n",
    "#netCDF output file formatting formatting\n",
    "tauname = ferretpath + savefile + \".nc\"\n",
    "taunc = nc.Dataset(tauname, \"r\")\n",
    "\n",
    "taus = []\n",
    "taus.append(taunc['tau_constant'][:])\n",
    "taus.append(taunc['tau_halfyear'][:])\n",
    "taus.append(taunc['tau_seasonal'][:])\n",
    "\n",
    "taunc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## the second argument in freq_std is the number of years in the sample - needs to change\n",
    "#p1_beg = [1951,1980]\n",
    "#p1_end = [1979,1993]\n",
    "#p2_beg = [1980,1994]\n",
    "#p2_end = [2007,2007]\n",
    "\n",
    "lats_1_p1_std = []\n",
    "lats_p1_std = []\n",
    "\n",
    "lats_1_p2_std = []\n",
    "lats_p2_std = []\n",
    "\n",
    "for mytau in taus:\n",
    "    #find standard deviation for each day and bin\n",
    "    #if the value for tau is NaN for a given time period (in other words, no bands happen), make tau=1\n",
    "    mytau[np.isnan(mytau)] = 1 \n",
    "    \n",
    "    lats_1_p1_std.append([ freq_std_tau(x, ye-yb+1, 15, 5, mytau) for x, yb, ye in zip(lats_1_p1, p1_beg, p1_end) ])\n",
    "    lats_p1_std.append([ freq_std_tau(x, ye-yb+1, 15, 5, mytau) for x, yb, ye in zip(lats_p1, p1_beg, p1_end) ])\n",
    "\n",
    "    lats_1_p2_std.append([ freq_std_tau(x, ye-yb+1, 15, 5, mytau) for x, yb, ye in zip(lats_1_p2, p2_beg, p2_end) ])\n",
    "    lats_p2_std.append([ freq_std_tau(x, ye-yb+1, 15, 5, mytau) for x, yb, ye in zip(lats_p2, p2_beg, p2_end) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
