{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.41 ms\n"
     ]
    }
   ],
   "source": [
    "## Non-parametric calculation of the significance of changes in intensity for intensity Hovmoller plots\n",
    "# based in large part on china_rain_diff.ipynb, and previous library of bootstrap codes (bootstrap.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 12.8 ms\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "%load_ext autotime\n",
    "from bootstrap import bs_means_diff, collect\n",
    "from shutil import copyfile\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.7 ms\n"
     ]
    }
   ],
   "source": [
    "#load hovmoller storage of intensity\n",
    "ferretpath = \"/Users/Siwen/Desktop/ferret/bin/\"\n",
    "hovfile = \"RDA_int_hov.nc\"\n",
    "file1 = ferretpath + hovfile\n",
    "hovf = nc.Dataset(file1, 'r')\n",
    "\n",
    "#load hovmoller climatology (mean, standard deviation and standard deviation of sample mean)\n",
    "#climofile = \"RDA_int_climo.nc\"\n",
    "#file2 = ferretpath + climofile\n",
    "#climof = nc.Dataset(file2, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5179\n",
      "8007\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "## BOOTSTRAPPING ##\n",
    "#from previous testing, determined that the autocorrelation time scale of rainfall is between\n",
    "#2 and 3 days. Will test both and see effect on p-values.\n",
    "\n",
    "#General expectation would be that longer block lengths will lead to fewer significant p-values\n",
    "#(smaller effective sample size\n",
    "\n",
    "##REWRITTEN SEPTEMBER 26, 2016\n",
    "#previous version had to run for potentially days at a time, whereas now it saves each new row as it completes it.\n",
    "\n",
    "#daysmth is defined above\n",
    "niter = 5000 #how many iterations each time?\n",
    "\n",
    "p1_beg = [1951,1980]\n",
    "p1_end = [1979,1993]\n",
    "p2_beg = [1980,1994]\n",
    "p2_end = [2007,2007]\n",
    "\n",
    "dayrange = 15 #what range of days are we smoothing over?\n",
    "latrange = 5 #what range of latitude are we smoothing over? (1 degree increments)\n",
    "\n",
    "save_path = \"RDA_int_diff_bootstrap_\" + str(niter) + \"iter_perm_median.nc\"\n",
    "main_folder = \"/Users/Siwen/RDA/Data/\"\n",
    "main_save = main_folder + save_path\n",
    "backup_folder = \"/Users/Siwen/Desktop/Ferret/bin/\"\n",
    "backup_save = backup_folder + save_path\n",
    "\n",
    "if os.path.isfile(main_save):\n",
    "    os.remove(main_save)\n",
    "    \n",
    "if os.path.isfile(backup_save):\n",
    "    os.remove(backup_save)\n",
    "\n",
    "fileout = nc.Dataset(main_save, \"w\")\n",
    "\n",
    "days_dim = fileout.createDimension('time', None)\n",
    "lat_dim = fileout.createDimension('lat', 22)\n",
    "dim_tuple = (\"time\",\"lat\")\n",
    "\n",
    "## PRIMARY FRONTS ONLY ##\n",
    "#actual bootstrapping loop - loads data from periods of interest, then performs bootstrapping calculations.\n",
    "for p1_b, p1_e, p2_b, p2_e in zip(p1_beg, p1_end, p2_beg, p2_end):\n",
    "    \n",
    "    years_p1= str(p1_b-1900) + str(\"{0:0=2d}\".format((p1_e-1900)%100))\n",
    "    print(years_p1)\n",
    "    years_p2= str(p2_b-1900) + str(\"{0:0=2d}\".format((p2_e-1900)%100))\n",
    "    print(years_p2)\n",
    "    years = years_p2 + '_' + years_p1\n",
    "    \n",
    "    int_p1 = hovf['int_1_hov_' + years_p1][:]\n",
    "    int_p2 = hovf['int_1_hov_' + years_p2][:]\n",
    "    \n",
    "    pval = np.empty([int_p1.shape[0], int_p1.shape[1]])\n",
    "    \n",
    "    #BOOTSTRAPPING CALCULATION OF P-VALUE OF INTENSITY CHANGES BETWEEN TIME PERIODS\n",
    "    for i in range(int_p1.shape[0]):\n",
    "        \n",
    "        print(i)\n",
    "        \n",
    "        for j in range(int_p1.shape[1]):\n",
    "            \n",
    "            s1 = collect(int_p1, i,j, dayrange, latrange)\n",
    "            s2 = collect(int_p2, i,j, dayrange, latrange)\n",
    "            \n",
    "            if ((len(s1) > 0) & (len(s2) > 0)):\n",
    "                #pval[i,j] = bs_means_diff(s2, s1, niter)[1]\n",
    "                pval[i,j] = bs_means_diff(s2, s1, niter, method='perm')[1]\n",
    "                \n",
    "            else:\n",
    "                pval[i,j] = np.NaN\n",
    "    \n",
    "    ## SAVE OUTPUT AS NETCDF FILE\n",
    "    #create variables inside netCDF file\n",
    "    pval_out_int_1 = fileout.createVariable(\"int_1_pval_\" + years, 'f8', dim_tuple)\n",
    "    pval_out_int_1[:] = ma.array(pval, mask = np.isnan(pval))\n",
    "    \n",
    "fileout.close()\n",
    "copyfile(main_save, backup_save) #backs file up in case of corruption\n",
    "hovf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ALL FRONTS ##\n",
    "#actual bootstrapping loop - loads data from periods of interest, then performs bootstrapping calculations.\n",
    "\n",
    "fileout = nc.Dataset(main_save, \"a\")\n",
    "hovf = nc.Dataset(file1, 'r')\n",
    "\n",
    "for p1_b, p1_e, p2_b, p2_e in zip(p1_beg, p1_end, p2_beg, p2_end):\n",
    "    \n",
    "    years_p1= str(p1_b-1900) + str(\"{0:0=2d}\".format((p1_e-1900)%100))\n",
    "    print(years_p1)\n",
    "    years_p2= str(p2_b-1900) + str(\"{0:0=2d}\".format((p2_e-1900)%100))\n",
    "    print(years_p2)\n",
    "    years = years_p2 + '_' + years_p1\n",
    "    \n",
    "    int_p1 = hovf['int_hov_' + years_p1][:]\n",
    "    int_p2 = hovf['int_hov_' + years_p2][:]\n",
    "    \n",
    "    pval = np.empty([int_p1.shape[0], int_p1.shape[1]])\n",
    "    \n",
    "    #BOOTSTRAPPING CALCULATION OF P-VALUE OF INTENSITY CHANGES BETWEEN TIME PERIODS\n",
    "    for i in range(int_p1.shape[0]):\n",
    "        \n",
    "        print(i)\n",
    "        \n",
    "        for j in range(int_p1.shape[1]):\n",
    "            \n",
    "            s1 = collect(int_p1, i,j, 15, 5)\n",
    "            s2 = collect(int_p2, i,j, 15, 5)\n",
    "            \n",
    "            if ((len(s1) > 0) & (len(s2) > 0)):\n",
    "                #pval[i,j] = bs_means_diff(s2, s1, niter)[1]\n",
    "                pval[i,j] = bs_means_diff(s2, s1, niter, method='perm')[1]\n",
    "                \n",
    "            else:\n",
    "                pval[i,j] = np.NaN\n",
    "    \n",
    "    ## SAVE OUTPUT AS NETCDF FILE\n",
    "    #create variables inside netCDF file\n",
    "    pval_out_int = fileout.createVariable(\"int_pval_\" + years, 'f8', dim_tuple)\n",
    "    pval_out_int[:] = ma.array(pval, mask = np.isnan(pval))\n",
    "\n",
    "fileout.close()\n",
    "copyfile(main_save, backup_save) #backs file up in case of corruption\n",
    "hovf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
